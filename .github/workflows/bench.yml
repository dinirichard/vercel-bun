name: Benchmark

on:
  workflow_dispatch:
    inputs:
      # API Configuration
      bench_api_domain:
        description: "Base URL for the API to benchmark"
        required: false
        default: "https://vercel-bun-bench.vercel.app"
        type: string
      endpoint:
        description: "API endpoint to test"
        required: false
        default: "/api/bun"
        type: choice
        options:
          - "/api/bun"
          - "/api/node"
          - "/api/bun/workload"
          - "/api/node/workload"

      # Test Selection
      run_burst_traffic:
        description: "Run burst traffic test"
        required: false
        default: false
        type: boolean
      run_cold_start:
        description: "Run cold start test"
        required: false
        default: false
        type: boolean
      run_concurrency:
        description: "Run concurrency test"
        required: false
        default: false
        type: boolean
      run_payload_size:
        description: "Run payload size test"
        required: false
        default: false
        type: boolean
      run_throughput:
        description: "Run throughput test"
        required: false
        default: false
        type: boolean
      run_warm_latency:
        description: "Run warm latency test"
        required: false
        default: false
        type: boolean

jobs:
  benchmark:
    runs-on: ubuntu-latest

    env:
      BENCH_API_DOMAIN: ${{ inputs.bench_api_domain }}
      ENDPOINT: ${{ inputs.endpoint }}
      DURATION: "60s"
      RPS: "100"
      MAX_RPS: "1000"
      MAX_CONNECTIONS: "1000"
      PAYLOAD_SIZE: "1024"
      ITERATIONS: "50"
      BURST_REQUESTS: "1000"
      BURST_DURATION: "2s"
      RAMP_UP_DURATION: "2m"
      SUSTAIN_DURATION: "3m"
      THINK_TIME: "0"
      COLD_START_WAIT_TIME_MINS: "5"
      COLD_START_ITERATIONS: "5"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Install dependencies
        run: |
          cd bench
          bun install

      - name: Create results directory
        run: |
          cd bench
          mkdir -p results

      - name: Run Burst Traffic Test
        if: ${{ inputs.run_burst_traffic == true }}
        run: |
          cd bench
          echo "üöÄ Running Burst Traffic Test"
          bun run bench:burst

      - name: Run Cold Start Test
        if: ${{ inputs.run_cold_start == true }}
        run: |
          cd bench
          echo "‚ùÑÔ∏è Running Cold Start Test"
          bun run bench:cold-start

      - name: Run Concurrency Test
        if: ${{ inputs.run_concurrency == true }}
        run: |
          cd bench
          echo "‚ö° Running Concurrency Test"
          bun run bench:concurrency

      - name: Run Payload Size Test
        if: ${{ inputs.run_payload_size == true }}
        run: |
          cd bench
          echo "üì¶ Running Payload Size Test"
          bun run bench:payload

      - name: Run Throughput Test
        if: ${{ inputs.run_throughput == true }}
        run: |
          cd bench
          echo "üöÄ Running Throughput Test"
          bun run bench:throughput

      - name: Run Warm Latency Test
        if: ${{ inputs.run_warm_latency == true }}
        run: |
          cd bench
          echo "üî• Running Warm Latency Test"
          bun run bench:warm

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.run_id }}
          path: bench/results/
          retention-days: 30
          if-no-files-found: ignore

      - name: Summary
        run: |
          echo "‚úÖ Benchmark tests completed!"
          echo "Tests run:"
          ${{ inputs.run_burst_traffic == true && 'echo "  - Burst Traffic Test"' || 'echo ""' }}
          ${{ inputs.run_cold_start == true && 'echo "  - Cold Start Test"' || 'echo ""' }}
          ${{ inputs.run_concurrency == true && 'echo "  - Concurrency Test"' || 'echo ""' }}
          ${{ inputs.run_payload_size == true && 'echo "  - Payload Size Test"' || 'echo ""' }}
          ${{ inputs.run_throughput == true && 'echo "  - Throughput Test"' || 'echo ""' }}
          ${{ inputs.run_warm_latency == true && 'echo "  - Warm Latency Test"' || 'echo ""' }}

          echo ""
          echo "üìÅ Results files have been uploaded as artifacts and can be downloaded from the Actions tab."
